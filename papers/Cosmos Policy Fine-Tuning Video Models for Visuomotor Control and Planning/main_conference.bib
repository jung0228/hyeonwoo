@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@inproceedings{miller2003automatic,
  title={Automatic grasp planning using shape primitives},
  author={Miller, Andrew T and Knoop, Steffen and Christensen, Henrik I and Allen, Peter K},
  booktitle={2003 IEEE International Conference on Robotics and Automation (Cat. No. 03CH37422)},
  volume={2},
  pages={1824--1829},
  year={2003},
  organization={IEEE}
}

@article{ciocarlie2009hand,
  title={Hand posture subspaces for dexterous robotic grasping},
  author={Ciocarlie, Matei T and Allen, Peter K},
  journal={The International Journal of Robotics Research},
  volume={28},
  number={7},
  pages={851--867},
  year={2009},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{pokorny2013classical,
  title={Classical grasp quality evaluation: New algorithms and theory},
  author={Pokorny, Florian T and Kragic, Danica},
  booktitle={2013 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={3493--3500},
  year={2013},
  organization={IEEE}
}

@article{catalano2014adaptive,
  title={Adaptive synergies for the design and control of the Pisa/IIT SoftHand},
  author={Catalano, Manuel G and Grioli, Giorgio and Farnioli, Edoardo and Serio, Alessandro and Piazza, Cristina and Bicchi, Antonio},
  journal={The International Journal of Robotics Research},
  volume={33},
  number={5},
  pages={768--782},
  year={2014},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{eppner2015exploitation,
  title={Exploitation of environmental constraints in human and robotic grasping},
  author={Eppner, Clemens and Deimel, Raphael and Alvarez-Ruiz, Jos{\'e} and Maertens, Marianne and Brock, Oliver},
  journal={The International Journal of Robotics Research},
  volume={34},
  number={7},
  pages={1021--1038},
  year={2015},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{dafle2014extrinsic,
  title={Extrinsic dexterity: In-hand manipulation with external forces},
  author={Dafle, Nikhil Chavan and Rodriguez, Alberto and Paolini, Robert and Tang, Bowei and Srinivasa, Siddhartha S and Erdmann, Michael and Mason, Matthew T and Lundberg, Ivan and Staab, Harald and Fuhlbrigge, Thomas},
  booktitle={2014 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={1578--1585},
  year={2014},
  organization={IEEE}
}

@article{schulman2014motion,
  title={Motion planning with sequential convex optimization and convex collision checking},
  author={Schulman, John and Duan, Yan and Ho, Jonathan and Lee, Alex and Awwal, Ibrahim and Bradlow, Henry and Pan, Jia and Patil, Sachin and Goldberg, Ken and Abbeel, Pieter},
  journal={The International Journal of Robotics Research},
  volume={33},
  number={9},
  pages={1251--1270},
  year={2014},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom B},
  journal={arXiv preprint arXiv:2005.14165},
  year={2020}
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}


@article{driess2023palm,
  title={Palm-e: An embodied multimodal language model},
  author={Driess, Danny and Xia, Fei and Sajjadi, Mehdi SM and Lynch, Corey and Chowdhery, Aakanksha and Ichter, Brian and Wahid, Ayzaan and Tompson, Jonathan and Vuong, Quan and Yu, Tianhe and others},
  journal={arXiv preprint arXiv:2303.03378},
  year={2023}
}

@inproceedings{brohan2023can,
  title={Do as i can, not as i say: Grounding language in robotic affordances},
  author={Brohan, Anthony and Chebotar, Yevgen and Finn, Chelsea and Hausman, Karol and Herzog, Alexander and Ho, Daniel and Ibarz, Julian and Irpan, Alex and Jang, Eric and Julian, Ryan and others},
  booktitle={Conference on robot learning},
  pages={287--318},
  year={2023},
  organization={PMLR}
}

@article{o2023open,
  title={Open x-embodiment: Robotic learning datasets and rt-x models},
  author={O'Neill, Abby and Rehman, Abdul and Gupta, Abhinav and Maddukuri, Abhiram and Gupta, Abhishek and Padalkar, Abhishek and Lee, Abraham and Pooley, Acorn and Gupta, Agrim and Mandlekar, Ajay and others},
  journal={arXiv preprint arXiv:2310.08864},
  year={2023}
}

@article{brohan2023rt,
  title={Rt-2: Vision-language-action models transfer web knowledge to robotic control},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Chen, Xi and Choromanski, Krzysztof and Ding, Tianli and Driess, Danny and Dubey, Avinava and Finn, Chelsea and others},
  journal={arXiv preprint arXiv:2307.15818},
  year={2023}
}

@article{kim2024openvla,
  title={OpenVLA: An Open-Source Vision-Language-Action Model},
  author={Kim, Moo Jin and Pertsch, Karl and Karamcheti, Siddharth and Xiao, Ted and Balakrishna, Ashwin and Nair, Suraj and Rafailov, Rafael and Foster, Ethan and Lam, Grace and Sanketi, Pannag and others},
  journal={arXiv preprint arXiv:2406.09246},
  year={2024}
}

@article{li2023vision,
  title={Vision-language foundation models as effective robot imitators},
  author={Li, Xinghang and Liu, Minghuan and Zhang, Hanbo and Yu, Cunjun and Xu, Jie and Wu, Hongtao and Cheang, Chilam and Jing, Ya and Zhang, Weinan and Liu, Huaping and others},
  journal={arXiv preprint arXiv:2311.01378},
  year={2023}
}

@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}

@article{chi2023diffusion,
  title={Diffusion policy: Visuomotor policy learning via action diffusion},
  author={Chi, Cheng and Xu, Zhenjia and Feng, Siyuan and Cousineau, Eric and Du, Yilun and Burchfiel, Benjamin and Tedrake, Russ and Song, Shuran},
  journal={The International Journal of Robotics Research},
  pages={02783649241273668},
  year={2023},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{liu2024libero,
  title={Libero: Benchmarking knowledge transfer for lifelong robot learning},
  author={Liu, Bo and Zhu, Yifeng and Gao, Chongkai and Feng, Yihao and Liu, Qiang and Zhu, Yuke and Stone, Peter},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{zhao2023learning,
  title={Learning fine-grained bimanual manipulation with low-cost hardware},
  author={Zhao, Tony Z and Kumar, Vikash and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:2304.13705},
  year={2023}
}

@article{wen2024tinyvla,
  title={TinyVLA: Towards Fast, Data-Efficient Vision-Language-Action Models for Robotic Manipulation},
  author={Wen, Junjie and Zhu, Yichen and Li, Jinming and Zhu, Minjie and Wu, Kun and Xu, Zhiyuan and Cheng, Ran and Shen, Chaomin and Peng, Yaxin and Feng, Feifei and others},
  journal={arXiv preprint arXiv:2409.12514},
  year={2024}
}

@article{liu2024rdt,
  title={RDT-1B: a Diffusion Foundation Model for Bimanual Manipulation},
  author={Liu, Songming and Wu, Lingxuan and Li, Bangguo and Tan, Hengkai and Chen, Huayu and Wang, Zhengyi and Xu, Ke and Su, Hang and Zhu, Jun},
  journal={arXiv preprint arXiv:2410.07864},
  year={2024}
}

@article{stone2023open,
  title={Open-world object manipulation using pre-trained vision-language models},
  author={Stone, Austin and Xiao, Ted and Lu, Yao and Gopalakrishnan, Keerthana and Lee, Kuang-Huei and Vuong, Quan and Wohlhart, Paul and Kirmani, Sean and Zitkovich, Brianna and Xia, Fei and others},
  journal={arXiv preprint arXiv:2303.00905},
  year={2023}
}

@article{ahn2022can,
  title={Do as i can, not as i say: Grounding language in robotic affordances},
  author={Ahn, Michael and Brohan, Anthony and Brown, Noah and Chebotar, Yevgen and Cortes, Omar and David, Byron and Finn, Chelsea and Fu, Chuyuan and Gopalakrishnan, Keerthana and Hausman, Karol and others},
  journal={arXiv preprint arXiv:2204.01691},
  year={2022}
}

@article{huang2023voxposer,
  title={Voxposer: Composable 3d value maps for robotic manipulation with language models},
  author={Huang, Wenlong and Wang, Chen and Zhang, Ruohan and Li, Yunzhu and Wu, Jiajun and Fei-Fei, Li},
  journal={arXiv preprint arXiv:2307.05973},
  year={2023}
}

@article{duan2024manipulate,
  title={Manipulate-anything: Automating real-world robots using vision-language models},
  author={Duan, Jiafei and Yuan, Wentao and Pumacay, Wilbert and Wang, Yi Ru and Ehsani, Kiana and Fox, Dieter and Krishna, Ranjay},
  journal={arXiv preprint arXiv:2406.18915},
  year={2024}
}


@inproceedings{nair2022r3m,
  title={R3m: A universal visual representation for robot manipulation},
  author={Nair, Suraj and Rajeswaran, Aravind and Kumar, Vikash and Finn, Chelsea and Gupta, Abhinav},
  booktitle={CoRL},
  year={2022}
}

@article{Karamcheti2023LanguageDrivenRL,
  title={Language-Driven Representation Learning for Robotics},
  author={Siddharth Karamcheti and Suraj Nair and Annie S. Chen and Thomas Kollar and Chelsea Finn and Dorsa Sadigh and Percy Liang},
  journal={ArXiv},
  year={2023},
  volume={abs/2302.12766},
  url={https://api.semanticscholar.org/CorpusID:257205716}
}


@inproceedings{gadre2023cows,
  title={Cows on pasture: Baselines and benchmarks for language-driven zero-shot object navigation},
  author={Gadre, Samir Yitzhak and Wortsman, Mitchell and Ilharco, Gabriel and Schmidt, Ludwig and Song, Shuran},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={23171--23181},
  year={2023}
}

@article{durante2024interactive,
  title={An interactive agent foundation model},
  author={Durante, Zane and Sarkar, Bidipta and Gong, Ran and Taori, Rohan and Noda, Yusuke and Tang, Paul and Adeli, Ehsan and Lakshmikanth, Shrinidhi Kowshika and Schulman, Kevin and Milstein, Arnold and others},
  journal={arXiv preprint arXiv:2402.05929},
  year={2024}
}


@inproceedings{huang2023embodied,
  title={An Embodied Generalist Agent in 3D World},
  author={Huang, Jiangyong and Yong, Silong and Ma, Xiaojian and Linghu, Xiongkun and Li, Puhao and Wang, Yan and Li, Qing and Zhu, Song-Chun and Jia, Baoxiong and Huang, Siyuan},
  booktitle={Proceedings of the International Conference on Machine Learning (ICML)},
  year={2024}
}

@article{zhen20243dvla,
  author = {Zhen, Haoyu and Qiu, Xiaowen and Chen, Peihao and Yang, Jincheng and Yan, Xin and Du, Yilun and Hong, Yining and Gan, Chuang},
  title = {3D-VLA: 3D Vision-Language-Action Generative World Model},
  journal = {arXiv preprint arXiv:2403.09631},
  year = {2024},
}


@misc{covariant_ai_2024,
author = "Andrew Sohn et al.",
title = "Introducing RFM-1: Giving robots human-like reasoning capabilities",
url = "https://covariant.ai/insights/introducing-rfm-1-giving-robots-human-like-reasoning-capabilities/",
year = "2024",
}


@article{wayve_ai_2024,
author = "Wayve",
title = "LINGO-2: Driving with Natural Language",
url = "https://wayve.ai/thinking/lingo-2-driving-with-language/",
year = "2024"}

@article{black2024pi_0,
  title={pi0: A Vision-Language-Action Flow Model for General Robot Control},
  author={Black, Kevin and Brown, Noah and Driess, Danny and Esmail, Adnan and Equi, Michael and Finn, Chelsea and Fusai, Niccolo and Groom, Lachy and Hausman, Karol and Ichter, Brian and others},
  journal={arXiv preprint arXiv:2410.24164},
  year={2024}
}

@article{zhao2024aloha,
  title={Aloha unleashed: A simple recipe for robot dexterity},
  author={Zhao, Tony Z and Tompson, Jonathan and Driess, Danny and Florence, Pete and Ghasemipour, Kamyar and Finn, Chelsea and Wahid, Ayzaan},
  journal={arXiv preprint arXiv:2410.13126},
  year={2024}
}

@inproceedings{nichol2021improved,
  title={Improved denoising diffusion probabilistic models},
  author={Nichol, Alexander Quinn and Dhariwal, Prafulla},
  booktitle={International conference on machine learning},
  pages={8162--8171},
  year={2021},
  organization={PMLR}
}


@misc{singh2022progpromptgeneratingsituatedrobot,
      title={ProgPrompt: Generating Situated Robot Task Plans using Large Language Models}, 
      author={Ishika Singh and Valts Blukis and Arsalan Mousavian and Ankit Goyal and Danfei Xu and Jonathan Tremblay and Dieter Fox and Jesse Thomason and Animesh Garg},
      year={2022},
      eprint={2209.11302},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2209.11302}, 
}

@misc{ahn2022icanisay,
      title={Do As I Can, Not As I Say: Grounding Language in Robotic Affordances}, 
      author={Michael Ahn and Anthony Brohan and Noah Brown and Yevgen Chebotar and Omar Cortes and Byron David and Chelsea Finn and Chuyuan Fu and Keerthana Gopalakrishnan and Karol Hausman and Alex Herzog and Daniel Ho and Jasmine Hsu and Julian Ibarz and Brian Ichter and Alex Irpan and Eric Jang and Rosario Jauregui Ruano and Kyle Jeffrey and Sally Jesmonth and Nikhil J Joshi and Ryan Julian and Dmitry Kalashnikov and Yuheng Kuang and Kuang-Huei Lee and Sergey Levine and Yao Lu and Linda Luu and Carolina Parada and Peter Pastor and Jornell Quiambao and Kanishka Rao and Jarek Rettinghouse and Diego Reyes and Pierre Sermanet and Nicolas Sievers and Clayton Tan and Alexander Toshev and Vincent Vanhoucke and Fei Xia and Ted Xiao and Peng Xu and Sichun Xu and Mengyuan Yan and Andy Zeng},
      year={2022},
      eprint={2204.01691},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2204.01691}, 
}

@misc{huang2022innermonologueembodiedreasoning,
      title={Inner Monologue: Embodied Reasoning through Planning with Language Models}, 
      author={Wenlong Huang and Fei Xia and Ted Xiao and Harris Chan and Jacky Liang and Pete Florence and Andy Zeng and Jonathan Tompson and Igor Mordatch and Yevgen Chebotar and Pierre Sermanet and Noah Brown and Tomas Jackson and Linda Luu and Sergey Levine and Karol Hausman and Brian Ichter},
      year={2022},
      eprint={2207.05608},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2207.05608}, 
}

@misc{huang2022languagemodelszeroshotplanners,
      title={Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents}, 
      author={Wenlong Huang and Pieter Abbeel and Deepak Pathak and Igor Mordatch},
      year={2022},
      eprint={2201.07207},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2201.07207}, 
}

@misc{song2023llmplannerfewshotgroundedplanning,
      title={LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models}, 
      author={Chan Hee Song and Jiaman Wu and Clayton Washington and Brian M. Sadler and Wei-Lun Chao and Yu Su},
      year={2023},
      eprint={2212.04088},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2212.04088}, 
}

@misc{zawalski2024roboticcontrolembodiedchainofthought,
      title={Robotic Control via Embodied Chain-of-Thought Reasoning}, 
      author={Michał Zawalski and William Chen and Karl Pertsch and Oier Mees and Chelsea Finn and Sergey Levine},
      year={2024},
      eprint={2407.08693},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2407.08693}, 
}

@inproceedings{perez2018film,
  title={Film: Visual reasoning with a general conditioning layer},
  author={Perez, Ethan and Strub, Florian and De Vries, Harm and Dumoulin, Vincent and Courville, Aaron},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}


@article{lipman2022flow,
  title={Flow matching for generative modeling},
  author={Lipman, Yaron and Chen, Ricky TQ and Ben-Hamu, Heli and Nickel, Maximilian and Le, Matt},
  journal={arXiv preprint arXiv:2210.02747},
  year={2022}
}

@inproceedings{ross2011reduction,
  title={A reduction of imitation learning and structured prediction to no-regret online learning},
  author={Ross, St{\'e}phane and Gordon, Geoffrey and Bagnell, Drew},
  booktitle={Proceedings of the fourteenth international conference on artificial intelligence and statistics},
  pages={627--635},
  year={2011},
  organization={JMLR Workshop and Conference Proceedings}
}

@article{team2024octo,
  title={Octo: An open-source generalist robot policy},
  author={Team, Octo Model and Ghosh, Dibya and Walke, Homer and Pertsch, Karl and Black, Kevin and Mees, Oier and Dasari, Sudeep and Hejna, Joey and Kreiman, Tobias and Xu, Charles and others},
  journal={arXiv preprint arXiv:2405.12213},
  year={2024}
}


@misc{pertsch2025fastefficientactiontokenization,
      title={FAST: Efficient Action Tokenization for Vision-Language-Action Models}, 
      author={Karl Pertsch and Kyle Stachowicz and Brian Ichter and Danny Driess and Suraj Nair and Quan Vuong and Oier Mees and Chelsea Finn and Sergey Levine},
      year={2025},
      eprint={2501.09747},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2501.09747}, 
}


@inproceedings{tan2019efficientnet,
  title={Efficientnet: Rethinking model scaling for convolutional neural networks},
  author={Tan, Mingxing and Le, Quoc},
  booktitle={International conference on machine learning},
  pages={6105--6114},
  year={2019},
  organization={PMLR}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{khazatsky2024droid,
  title={Droid: A large-scale in-the-wild robot manipulation dataset},
  author={Khazatsky, Alexander and Pertsch, Karl and Nair, Suraj and Balakrishna, Ashwin and Dasari, Sudeep and Karamcheti, Siddharth and Nasiriany, Soroush and Srirama, Mohan Kumar and Chen, Lawrence Yunliang and Ellis, Kirsty and others},
  journal={arXiv preprint arXiv:2403.12945},
  year={2024}
}

@article{sanh2019distilbert,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Sanh, V},
  journal={arXiv preprint arXiv:1910.01108},
  year={2019}
}


@article{oquab2023dinov2,
  title={Dinov2: Learning robust visual features without supervision},
  author={Oquab, Maxime and Darcet, Timoth{\'e}e and Moutakanni, Th{\'e}o and Vo, Huy and Szafraniec, Marc and Khalidov, Vasil and Fernandez, Pierre and Haziza, Daniel and Massa, Francisco and El-Nouby, Alaaeldin and others},
  journal={arXiv preprint arXiv:2304.07193},
  year={2023}
}

@inproceedings{zhai2023sigmoid,
  title={Sigmoid loss for language image pre-training},
  author={Zhai, Xiaohua and Mustafa, Basil and Kolesnikov, Alexander and Beyer, Lucas},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={11975--11986},
  year={2023}
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@article{lee2024behavior,
  title={Behavior generation with latent actions},
  author={Lee, Seungjae and Wang, Yibin and Etukuru, Haritheja and Kim, H Jin and Shafiullah, Nur Muhammad Mahi and Pinto, Lerrel},
  journal={arXiv preprint arXiv:2403.03181},
  year={2024}
}

@article{van2017neural,
  title={Neural discrete representation learning},
  author={Van Den Oord, Aaron and Vinyals, Oriol and others},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{mentzer2023finite,
  title={Finite scalar quantization: Vq-vae made simple},
  author={Mentzer, Fabian and Minnen, David and Agustsson, Eirikur and Tschannen, Michael},
  journal={arXiv preprint arXiv:2309.15505},
  year={2023}
}

@article{fu2024mobile,
  title={Mobile aloha: Learning bimanual mobile manipulation with low-cost whole-body teleoperation},
  author={Fu, Zipeng and Zhao, Tony Z and Finn, Chelsea},
  journal={arXiv preprint arXiv:2401.02117},
  year={2024}
}

@article{karamcheti2024prismatic,
  title={Prismatic vlms: Investigating the design space of visually-conditioned language models},
  author={Karamcheti, Siddharth and Nair, Suraj and Balakrishna, Ashwin and Liang, Percy and Kollar, Thomas and Sadigh, Dorsa},
  journal={arXiv preprint arXiv:2402.07865},
  year={2024}
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{liu2024bidirectional,
  title={Bidirectional Decoding: Improving Action Chunking via Closed-Loop Resampling},
  author={Liu, Yuejiang and Hamid, Jubayer Ibn and Xie, Annie and Lee, Yoonho and Du, Maximilian and Finn, Chelsea},
  journal={arXiv preprint arXiv:2408.17355},
  year={2024}
}


@article{shi2024yell,
  title={Yell at your robot: Improving on-the-fly from language corrections},
  author={Shi, Lucy Xiaoyang and Hu, Zheyuan and Zhao, Tony Z and Sharma, Archit and Pertsch, Karl and Luo, Jianlan and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:2403.12910},
  year={2024}
}

@article{majumdar2023we,
  title={Where are we in the search for an artificial visual cortex for embodied intelligence?},
  author={Majumdar, Arjun and Yadav, Karmesh and Arnaud, Sergio and Ma, Jason and Chen, Claire and Silwal, Sneha and Jain, Aryan and Berges, Vincent-Pierre and Wu, Tingfan and Vakil, Jay and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={655--677},
  year={2023}
}

@article{ma2022vip,
  title={Vip: Towards universal visual reward and representation via value-implicit pre-training},
  author={Ma, Yecheng Jason and Sodhani, Shagun and Jayaraman, Dinesh and Bastani, Osbert and Kumar, Vikash and Zhang, Amy},
  journal={arXiv preprint arXiv:2210.00030},
  year={2022}
}


@inproceedings{ma2023liv,
  title={Liv: Language-image representations and rewards for robotic control},
  author={Ma, Yecheng Jason and Kumar, Vikash and Zhang, Amy and Bastani, Osbert and Jayaraman, Dinesh},
  booktitle={International Conference on Machine Learning},
  pages={23301--23320},
  year={2023},
  organization={PMLR}
}


@misc{belkhale2024minivla,
      title={MiniVLA: A Better VLA with a Smaller Footprint}, 
      author={Suneel Belkhale and Dorsa Sadigh},
      url={https://github.com/Stanford-ILIAD/openvla-mini},
      year={2024},
}

@article{tian2024predictive,
  title={Predictive Inverse Dynamics Models are Scalable Learners for Robotic Manipulation},
  author={Tian, Yang and Yang, Sizhe and Zeng, Jia and Wang, Ping and Lin, Dahua and Dong, Hao and Pang, Jiangmiao},
  journal={arXiv preprint arXiv:2412.15109},
  year={2024}
}

@misc{hou2025diffusiontransformerpolicyscaling,
      title={Diffusion Transformer Policy: Scaling Diffusion Transformer for Generalist Vision-Language-Action Learning}, 
      author={Zhi Hou and Tianyi Zhang and Yuwen Xiong and Hengjun Pu and Chengyang Zhao and Ronglei Tong and Yu Qiao and Jifeng Dai and Yuntao Chen},
      year={2025},
      eprint={2410.15959},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2410.15959}, 
}

@misc{reuss2024multimodaldiffusiontransformerlearning,
      title={Multimodal Diffusion Transformer: Learning Versatile Behavior from Multimodal Goals}, 
      author={Moritz Reuss and Ömer Erdinç Yağmurlu and Fabian Wenzel and Rudolf Lioutikov},
      year={2024},
      eprint={2407.05996},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2407.05996}, 
}

@article{song2020denoising,
  title={Denoising diffusion implicit models},
  author={Song, Jiaming and Meng, Chenlin and Ermon, Stefano},
  journal={arXiv preprint arXiv:2010.02502},
  year={2020}
}

@article{lu2022dpm,
  title={Dpm-solver++: Fast solver for guided sampling of diffusion probabilistic models},
  author={Lu, Cheng and Zhou, Yuhao and Bao, Fan and Chen, Jianfei and Li, Chongxuan and Zhu, Jun},
  journal={arXiv preprint arXiv:2211.01095},
  year={2022}
}

@article{hendrycks2016gaussian,
  title={Gaussian error linear units (gelus)},
  author={Hendrycks, Dan and Gimpel, Kevin},
  journal={arXiv preprint arXiv:1606.08415},
  year={2016}
}

@article{zhou2023language,
  title={Language-conditioned learning for robotic manipulation: A survey},
  author={Zhou, Hongkuan and Yao, Xiangtong and Meng, Yuan and Sun, Siming and Bing, Zhenshan and Huang, Kai and Knoll, Alois},
  journal={arXiv preprint arXiv:2312.10807},
  year={2023}
}

@article{pan2024vision,
  title={Vision-language-action model and diffusion policy switching enables dexterous control of an anthropomorphic hand},
  author={Pan, Cheng and Junge, Kai and Hughes, Josie},
  journal={arXiv preprint arXiv:2410.14022},
  year={2024}
}

@article{julg2025refined,
  title={Refined Policy Distillation: From VLA Generalists to RL Experts},
  author={J{\"u}lg, Tobias and Burgard, Wolfram and Walter, Florian},
  journal={arXiv preprint arXiv:2503.05833},
  year={2025}
}

@inproceedings{walke2023bridgedata,
  title={Bridgedata v2: A dataset for robot learning at scale},
  author={Walke, Homer Rich and Black, Kevin and Zhao, Tony Z and Vuong, Quan and Zheng, Chongyi and Hansen-Estruch, Philippe and He, Andre Wang and Myers, Vivek and Kim, Moo Jin and Du, Max and others},
  booktitle={Conference on Robot Learning},
  pages={1723--1736},
  year={2023},
  organization={PMLR}
}

@article{kim2025fine,
  title={Fine-tuning vision-language-action models: Optimizing speed and success},
  author={Kim, Moo Jin and Finn, Chelsea and Liang, Percy},
  journal={arXiv preprint arXiv:2502.19645},
  year={2025}
}

@article{li2025cogvla,
  title={CogVLA: Cognition-Aligned Vision-Language-Action Model via Instruction-Driven Routing \& Sparsification},
  author={Li, Wei and Zhang, Renshan and Shao, Rui and He, Jie and Nie, Liqiang},
  journal={arXiv preprint arXiv:2508.21046},
  year={2025}
}

@article{intelligence2025pi,
  title={{$\pi_{0.5}$: a Vision-Language-Action Model with Open-World Generalization}},
  author={Intelligence, Physical and Black, Kevin and Brown, Noah and Darpinian, James and Dhabalia, Karan and Driess, Danny and Esmail, Adnan and Equi, Michael and Finn, Chelsea and Fusai, Niccolo and others},
  journal={arXiv preprint arXiv:2504.16054},
  year={2025}
}

@article{li2025unified,
  title={Unified video action model},
  author={Li, Shuang and Gao, Yihuai and Sadigh, Dorsa and Song, Shuran},
  journal={arXiv preprint arXiv:2503.00200},
  year={2025}
}

@article{sun2025geovla,
  title={GeoVLA: Empowering 3D Representations in Vision-Language-Action Models},
  author={Sun, Lin and Xie, Bin and Liu, Yingfei and Shi, Hao and Wang, Tiancai and Cao, Jiale},
  journal={arXiv preprint arXiv:2508.09071},
  year={2025}
}

@article{bu2025univla,
  title={Univla: Learning to act anywhere with task-centric latent actions},
  author={Bu, Qingwen and Yang, Yanting and Cai, Jisong and Gao, Shenyuan and Ren, Guanghui and Yao, Maoqing and Luo, Ping and Li, Hongyang},
  journal={arXiv preprint arXiv:2505.06111},
  year={2025}
}

@article{liang2025video,
  title={Video Generators are Robot Policies},
  author={Liang, Junbang and Tokmakov, Pavel and Liu, Ruoshi and Sudhakar, Sruthi and Shah, Paarth and Ambrus, Rares and Vondrick, Carl},
  journal={arXiv preprint arXiv:2508.00795},
  year={2025}
}

@article{bhat20253d,
  title={3D CAVLA: Leveraging Depth and 3D Context to Generalize Vision Language Action Models for Unseen Tasks},
  author={Bhat, Vineet and Lan, Yu-Hsiang and Krishnamurthy, Prashanth and Karri, Ramesh and Khorrami, Farshad},
  journal={arXiv preprint arXiv:2505.05800},
  year={2025}
}

@article{zhu2025unified,
  title={Unified world models: Coupling video and action diffusion for pretraining on large robotic datasets},
  author={Zhu, Chuning and Yu, Raymond and Feng, Siyuan and Burchfiel, Benjamin and Shah, Paarth and Gupta, Abhishek},
  journal={arXiv preprint arXiv:2504.02792},
  year={2025}
}

@misc{nvidia2025cosmosworldfoundationmodel,
      title={Cosmos World Foundation Model Platform for Physical AI}, 
      author={NVIDIA and : and Niket Agarwal and Arslan Ali and Maciej Bala and Yogesh Balaji and Erik Barker and Tiffany Cai and Prithvijit Chattopadhyay and Yongxin Chen and Yin Cui and Yifan Ding and Daniel Dworakowski and Jiaojiao Fan and Michele Fenzi and Francesco Ferroni and Sanja Fidler and Dieter Fox and Songwei Ge and Yunhao Ge and Jinwei Gu and Siddharth Gururani and Ethan He and Jiahui Huang and Jacob Huffman and Pooya Jannaty and Jingyi Jin and Seung Wook Kim and Gergely Klár and Grace Lam and Shiyi Lan and Laura Leal-Taixe and Anqi Li and Zhaoshuo Li and Chen-Hsuan Lin and Tsung-Yi Lin and Huan Ling and Ming-Yu Liu and Xian Liu and Alice Luo and Qianli Ma and Hanzi Mao and Kaichun Mo and Arsalan Mousavian and Seungjun Nah and Sriharsha Niverty and David Page and Despoina Paschalidou and Zeeshan Patel and Lindsey Pavao and Morteza Ramezanali and Fitsum Reda and Xiaowei Ren and Vasanth Rao Naik Sabavat and Ed Schmerling and Stella Shi and Bartosz Stefaniak and Shitao Tang and Lyne Tchapmi and Przemek Tredak and Wei-Cheng Tseng and Jibin Varghese and Hao Wang and Haoxiang Wang and Heng Wang and Ting-Chun Wang and Fangyin Wei and Xinyue Wei and Jay Zhangjie Wu and Jiashu Xu and Wei Yang and Lin Yen-Chen and Xiaohui Zeng and Yu Zeng and Jing Zhang and Qinsheng Zhang and Yuxuan Zhang and Qingqing Zhao and Artur Zolkowski},
      year={2025},
      eprint={2501.03575},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2501.03575}, 
}

@article{karras2022elucidating,
  title={Elucidating the design space of diffusion-based generative models},
  author={Karras, Tero and Aittala, Miika and Aila, Timo and Laine, Samuli},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={26565--26577},
  year={2022}
}

@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@article{wan2025,
      title={Wan: Open and Advanced Large-Scale Video Generative Models}, 
      author={Team Wan and Ang Wang and Baole Ai and Bin Wen and Chaojie Mao and Chen-Wei Xie and Di Chen and Feiwu Yu and Haiming Zhao and Jianxiao Yang and Jianyuan Zeng and Jiayu Wang and Jingfeng Zhang and Jingren Zhou and Jinkai Wang and Jixuan Chen and Kai Zhu and Kang Zhao and Keyu Yan and Lianghua Huang and Mengyang Feng and Ningyi Zhang and Pandeng Li and Pingyu Wu and Ruihang Chu and Ruili Feng and Shiwei Zhang and Siyang Sun and Tao Fang and Tianxing Wang and Tianyi Gui and Tingyu Weng and Tong Shen and Wei Lin and Wei Wang and Wei Wang and Wenmeng Zhou and Wente Wang and Wenting Shen and Wenyuan Yu and Xianzhong Shi and Xiaoming Huang and Xin Xu and Yan Kou and Yangyu Lv and Yifei Li and Yijing Liu and Yiming Wang and Yingya Zhang and Yitong Huang and Yong Li and You Wu and Yu Liu and Yulin Pan and Yun Zheng and Yuntao Hong and Yupeng Shi and Yutong Feng and Zeyinzi Jiang and Zhen Han and Zhi-Fan Wu and Ziyu Liu},
      journal = {arXiv preprint arXiv:2503.20314},
      year={2025}
}

@inproceedings{peebles2023scalable,
  title={Scalable diffusion models with transformers},
  author={Peebles, William and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={4195--4205},
  year={2023}
}


@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of machine learning research},
  volume={21},
  number={140},
  pages={1--67},
  year={2020}
}

@article{hou2025dita,
  title={Dita: Scaling diffusion transformer for generalist vision-language-action policy},
  author={Hou, Zhi and Zhang, Tianyi and Xiong, Yuwen and Duan, Haonan and Pu, Hengjun and Tong, Ronglei and Zhao, Chengyang and Zhu, Xizhou and Qiao, Yu and Dai, Jifeng and others},
  journal={arXiv preprint arXiv:2503.19757},
  year={2025}
}

@article{zhong2025flowvla,
  title={FlowVLA: Thinking in Motion with a Visual Chain of Thought},
  author={Zhong, Zhide and Yan, Haodong and Li, Junfeng and Liu, Xiangchen and Gong, Xin and Song, Wenxuan and Chen, Jiayi and Li, Haoang},
  journal={arXiv preprint arXiv:2508.18269},
  year={2025}
}

@article{hu2024video,
  title={Video prediction policy: A generalist robot policy with predictive visual representations},
  author={Hu, Yucheng and Guo, Yanjiang and Wang, Pengchao and Chen, Xiaoyu and Wang, Yen-Jen and Zhang, Jianke and Sreenath, Koushil and Lu, Chaochao and Chen, Jianyu},
  journal={arXiv preprint arXiv:2412.14803},
  year={2024}
}

@article{liao2025genie,
  title={Genie envisioner: A unified world foundation platform for robotic manipulation},
  author={Liao, Yue and Zhou, Pengfei and Huang, Siyuan and Yang, Donglin and Chen, Shengcong and Jiang, Yuxin and Hu, Yue and Cai, Jingbin and Liu, Si and Luo, Jianlan and others},
  journal={arXiv preprint arXiv:2508.05635},
  year={2025}
}

@misc{unifolm-wma-0,
  author       = {Unitree},
  title        = {UnifoLM-WMA-0: A World-Model-Action (WMA) Framework under UnifoLM Family},
  year         = {2025},
}

@article{feng2025vidar,
  title={Vidar: Embodied Video Diffusion Model for Generalist Bimanual Manipulation},
  author={Feng, Yao and Tan, Hengkai and Mao, Xinyi and Liu, Guodong and Huang, Shuhe and Xiang, Chendong and Su, Hang and Zhu, Jun},
  journal={arXiv preprint arXiv:2507.12898},
  year={2025}
}

@article{yang2025roboenvision,
  title={RoboEnvision: A Long-Horizon Video Generation Model for Multi-Task Robot Manipulation},
  author={Yang, Liudi and Bai, Yang and Eskandar, George and Shen, Fengyi and Altillawi, Mohammad and Chen, Dong and Majumder, Soumajit and Liu, Ziyuan and Kutyniok, Gitta and Valada, Abhinav},
  journal={arXiv preprint arXiv:2506.22007},
  year={2025}
}

@article{wang2025latent,
  title={Latent Policy Steering with Embodiment-Agnostic Pretrained World Models},
  author={Wang, Yiqi and Verghese, Mrinal and Schneider, Jeff},
  journal={arXiv preprint arXiv:2507.13340},
  year={2025}
}


@article{sutton1991dyna,
author = {Sutton, Richard S.},
title = {Dyna, an integrated architecture for learning, planning, and reacting},
year = {1991},
issue_date = {Aug. 1991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {4},
issn = {0163-5719},
url = {https://doi.org/10.1145/122344.122377},
doi = {10.1145/122344.122377},
abstract = {Dyna is an AI architecture that integrates learning, planning, and reactive execution. Learning methods are used in Dyna both for compiling planning results and for updating a model of the effects of the agent's actions on the world. Planning is incremental and can use the probabilistic and ofttimes incorrect world models generated by learning processes. Execution is fully reactive in the sense that no planning intervenes between perception and action. Dyna relies on machine learning methods for learning from examples---these are among the basic building blocks making up the architecture---yet is not tied to any particular method. This paper briefly introduces Dyna and discusses its strengths and weaknesses with respect to other architectures.},
journal = {SIGART Bull.},
month = jul,
pages = {160–163},
numpages = {4}
}

@article{janner2019trust,
  title={When to trust your model: Model-based policy optimization},
  author={Janner, Michael and Fu, Justin and Zhang, Marvin and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{racaniere2017imagination,
  title={Imagination-augmented agents for deep reinforcement learning},
  author={Racani{\`e}re, S{\'e}bastien and Weber, Th{\'e}ophane and Reichert, David and Buesing, Lars and Guez, Arthur and Jimenez Rezende, Danilo and Puigdom{\`e}nech Badia, Adri{\`a} and Vinyals, Oriol and Heess, Nicolas and Li, Yujia and others},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{hafner2019dream,
  title={Dream to control: Learning behaviors by latent imagination},
  author={Hafner, Danijar and Lillicrap, Timothy and Ba, Jimmy and Norouzi, Mohammad},
  journal={arXiv preprint arXiv:1912.01603},
  year={2019}
}

@article{hafner2020mastering,
  title={Mastering atari with discrete world models},
  author={Hafner, Danijar and Lillicrap, Timothy and Norouzi, Mohammad and Ba, Jimmy},
  journal={arXiv preprint arXiv:2010.02193},
  year={2020}
}

@article{hafner2023mastering,
  title={Mastering diverse domains through world models},
  author={Hafner, Danijar and Pasukonis, Jurgis and Ba, Jimmy and Lillicrap, Timothy},
  journal={arXiv preprint arXiv:2301.04104},
  year={2023}
}

@article{hansen2022temporal,
  title={Temporal difference learning for model predictive control},
  author={Hansen, Nicklas and Wang, Xiaolong and Su, Hao},
  journal={arXiv preprint arXiv:2203.04955},
  year={2022}
}

@article{hansen2023td,
  title={Td-mpc2: Scalable, robust world models for continuous control},
  author={Hansen, Nicklas and Su, Hao and Wang, Xiaolong},
  journal={arXiv preprint arXiv:2310.16828},
  year={2023}
}

@article{zheng2025flare,
  title={FLARE: Robot learning with implicit world modeling},
  author={Zheng, Ruijie and Wang, Jing and Reed, Scott and Bjorck, Johan and Fang, Yu and Hu, Fengyuan and Jang, Joel and Kundalia, Kaushil and Lin, Zongyu and Magne, Loic and others},
  journal={arXiv preprint arXiv:2505.15659},
  year={2025}
}

@article{jain2025smooth,
  title={A Smooth Sea Never Made a Skilled SAILOR: Robust Imitation via Learning to Search},
  author={Jain, Arnav Kumar and Mohta, Vibhakar and Kim, Subin and Bhardwaj, Atiksh and Ren, Juntao and Feng, Yunhai and Choudhury, Sanjiban and Swamy, Gokul},
  journal={arXiv preprint arXiv:2506.05294},
  year={2025}
}

@article{yang2024cogvideox,
  title={Cogvideox: Text-to-video diffusion models with an expert transformer},
  author={Yang, Zhuoyi and Teng, Jiayan and Zheng, Wendi and Ding, Ming and Huang, Shiyu and Xu, Jiazheng and Yang, Yuanming and Hong, Wenyi and Zhang, Xiaohan and Feng, Guanyu and others},
  journal={arXiv preprint arXiv:2408.06072},
  year={2024}
}

@article{bao2024vidu,
  title={Vidu: a highly consistent, dynamic and skilled text-to-video generator with diffusion models},
  author={Bao, Fan and Xiang, Chendong and Yue, Gang and He, Guande and Zhu, Hongzhou and Zheng, Kaiwen and Zhao, Min and Liu, Shilong and Wang, Yaole and Zhu, Jun},
  journal={arXiv preprint arXiv:2405.04233},
  year={2024}
}

@article{kong2024hunyuanvideo,
  title={Hunyuanvideo: A systematic framework for large video generative models},
  author={Kong, Weijie and Tian, Qi and Zhang, Zijian and Min, Rox and Dai, Zuozhuo and Zhou, Jin and Xiong, Jiangfeng and Li, Xin and Wu, Bo and Zhang, Jianwei and others},
  journal={arXiv preprint arXiv:2412.03603},
  year={2024}
}

@article{zheng2024open,
  title={Open-sora: Democratizing efficient video production for all},
  author={Zheng, Zangwei and Peng, Xiangyu and Yang, Tianji and Shen, Chenhui and Li, Shenggui and Liu, Hongxin and Zhou, Yukun and Li, Tianyi and You, Yang},
  journal={arXiv preprint arXiv:2412.20404},
  year={2024}
}




@article{bjorck2025gr00t,
  title={Gr00t n1: An open foundation model for generalist humanoid robots},
  author={Bjorck, Johan and Casta{\~n}eda, Fernando and Cherniadev, Nikita and Da, Xingye and Ding, Runyu and Fan, Linxi and Fang, Yu and Fox, Dieter and Hu, Fengyuan and Huang, Spencer and others},
  journal={arXiv preprint arXiv:2503.14734},
  year={2025}
}

@article{koo2025hamlet,
  title={HAMLET: Switch your Vision-Language-Action Model into a History-Aware Policy},
  author={Koo, Myungkyu and Choi, Daewon and Kim, Taeyoung and Lee, Kyungmin and Kim, Changyeon and Seo, Youngyo and Shin, Jinwoo},
  journal={arXiv preprint arXiv:2510.00695},
  year={2025}
}

@article{jang2025dreamgen,
  title={DreamGen: Unlocking Generalization in Robot Learning through Video World Models},
  author={Jang, Joel and Ye, Seonghyeon and Lin, Zongyu and Xiang, Jiannan and Bjorck, Johan and Fang, Yu and Hu, Fengyuan and Huang, Spencer and Kundalia, Kaushil and Lin, Yen-Chen and others},
  journal={arXiv preprint arXiv:2505.12705},
  year={2025}
}

@article{han2024dual,
  title={A dual process vla: Efficient robotic manipulation leveraging vlm},
  author={Han, ByungOk and Kim, Jaehong and Jang, Jinhyeok},
  journal={arXiv preprint arXiv:2410.15549},
  year={2024}
}

@article{won2025dual,
  title={Dual-Stream Diffusion for World-Model Augmented Vision-Language-Action Model},
  author={Won, John and Lee, Kyungmin and Jang, Huiwon and Kim, Dongyoung and Shin, Jinwoo},
  journal={arXiv preprint arXiv:2510.27607},
  year={2025}
}


@article{nasiriany2024robocasa,
  title={Robocasa: Large-scale simulation of everyday tasks for generalist robots},
  author={Nasiriany, Soroush and Maddukuri, Abhiram and Zhang, Lance and Parikh, Adeet and Lo, Aaron and Joshi, Abhishek and Mandlekar, Ajay and Zhu, Yuke},
  journal={arXiv preprint arXiv:2406.02523},
  year={2024}
}

@article{mandlekar2023mimicgen,
  title={Mimicgen: A data generation system for scalable robot learning using human demonstrations},
  author={Mandlekar, Ajay and Nasiriany, Soroush and Wen, Bowen and Akinola, Iretiayo and Narang, Yashraj and Fan, Linxi and Zhu, Yuke and Fox, Dieter},
  journal={arXiv preprint arXiv:2310.17596},
  year={2023}
}

@article{he2024learning,
  title={Learning an actionable discrete diffusion policy via large-scale actionless video pre-training},
  author={He, Haoran and Bai, Chenjia and Pan, Ling and Zhang, Weinan and Zhao, Bin and Li, Xuelong},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={31124--31153},
  year={2024}
}